% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{amsmath}

\usepackage[nottoc,notlot,notlof]{tocbibind} % get the bibliography to be listed in the ToC as an unnumbered sectional unit

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}         % X11 colour names
\usepackage{listings}       % Source code listings
\usepackage{courier}        % courier font
\usepackage{textcomp}       % straight quotes
\lstset{
  basicstyle=\ttfamily
, commentstyle=\color{Green}
, keywordstyle=\bfseries\color{RoyalBlue}
, showspaces=false
, showstringspaces=false
, breaklines=true
, breakatwhitespace=true
, framextopmargin=50pt
, columns=fullflexible,keepspaces
, escapeinside={(!}{!)}
, upquote=true
%, frame=bottomline
      }

\newcommand{\lml}{\lstset{language=ML,morekeywords={match,int,char,string,list,option}}}
\newcommand{\lc}{\lstset{language=C,morekeywords={}}}
\newcommand{\lnone}{\lstset{language={},morekeywords={}}}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Cheng Sun}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{An observable OCaml via C and \texttt{liballocs}} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Churchill College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Cheng Sun                       \\
College:            & \bf Churchill College                     \\
Project Title:      & \bf An observable OCaml via C and \texttt{liballocs} \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2017  \\
Word Count:         & \bf 1587\footnotemark[1] \\
Project Originator: & Stephen Kell                    \\
Supervisor:         & Stephen Kell                    \\
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \lnone\lstinline!detex diss.tex | tr -cd '0-9A-Za-z \\n' | wc -w!
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

%TODO
%To write a demonstration dissertation\footnote{A normal footnote without the
%complication of being in a table.} using \LaTeX\ to save
%student's time when writing their own dissertations. The dissertation
%should illustrate how to use the more common \LaTeX\ constructs. It
%should include pictures and diagrams to show how these can be
%incorporated into the dissertation.  It should contain the entire
%\LaTeX\ source of the dissertation and the makefile.  It should
%explain how to construct an MSDOS disk of the dissertation in
%Postscript format that can be used by the book shop for printing, and,
%finally, it should have the prescribed layout and format of a diploma
%dissertation.


\section*{Work Completed}

%TODO
%All that has been completed appears in this dissertation.

\section*{Special Difficulties}

%TODO
%Learning how to incorporate encapulated postscript into a \LaTeX\
%document on both Ubuntu Linux and OS X.
 
\newpage
\section*{Declaration}

I, Cheng Sun of Churchill College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

\newpage
\section*{Acknowledgements}

%TODO
%This document owes much to an earlier version written by Simon Moore
%\cite{Moore95}.  His help, encouragement and advice was greatly 
%appreciated.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

OCaml is one of the most commonly used members of the ML family of functional
languages. It is popular for its expressivity, type system and performance.
However, there is not as of yet a good story for debugging OCaml programs, and
observing their behaviour at runtime.

\begin{enumerate}
    \item \textbf{Feasibility}: it would be nice to know whether it is
        technically possible to compile from OCaml code to C. In particular OCaml's
        \lstinline!Lambda! Intermediate Representation is a fairly flexible and
        expressive target, which is garnering increased attention as a possible
        target IR for compiler frontends of other languages \cite{dolan16};
    \item \textbf{Performance}: C has very mature toolchains that have been
        refined and optimised over tens of years. It would be nice to leverage
        the optimisations that the GCC and Clang compilers can provide for
        free;
    \item \textbf{Observability}: gdb is a very mature debugger for C, which
        far surpasses OCaml's in power;
    \item \textbf{Portability}: C can be compiled on a diverse range of
        platforms. It would be nice to know that OCaml code could theoretically
        run on these platforms with minimal changes.
\end{enumerate}

The OCaml bytecode debugger, \lstinline{ocamldebug}, forms part of the core
OCaml toolchain. One major problem is that \lstinline{ocamldebug} is unable to
``see through'' polymorphism. For instance, suppose we would like to debug the
following polymorphic list-reverse function, which has type
\lml\lstinline{'a list -> 'a list}:

\begin{lstlisting}
let my_rev lst =
  match lst with
  | [] -> []
  | x::xs -> List.append xs [x]

let result = my_rev [1; 2; 3]
\end{lstlisting}\lnone

Now let's try to debug the function with \lstinline{ocamldebug}.

\begin{lstlisting}
$ (!\aftergroup\bfseries!)ocamlc -g -o my_rev my_rev.ml(!\aftergroup\mdseries!)
$ (!\aftergroup\bfseries!)ocamldebug my_rev(!\aftergroup\mdseries!)
        OCaml Debugger version 4.02.3

(ocd) (!\aftergroup\bfseries!)break @ My_rev 1(!\aftergroup\mdseries!)
Loading program... done.
Breakpoint 1 at 21600: file my_rev.ml, line 2, characters 3-62
(ocd) (!\aftergroup\bfseries!)run(!\aftergroup\mdseries!)
Time: 12 - pc: 21600 - module My_rev
Breakpoint: 1
2   <|b|>match lst with
(ocd) (!\aftergroup\bfseries!)print lst(!\aftergroup\mdseries!)
lst: 'a list = [<poly>; <poly>; <poly>]
\end{lstlisting}

Note that \lstinline{ocamldebug} is unable to display the contents of the input
list, as it does not know the concrete type that the type variable
\lstinline{'a} is instantiated with for this invocation.

There are many other deficiencies with the OCaml debugger, mostly stemming from
its immaturity and lack of features. These issues mean that when debugging
OCaml code, one often has to resort to ``printf debugging'' instead.

The aim of this project is to investigate whether the experience of debugging
and observing the runtime behaviour of OCaml programs could be improved by
utilising the mature C toolchain. My goal is to write a translator that
compiles OCaml code into equivalent C code, whilst maintaining a well-defined
mapping between the two (in terms of variable names, types, and so on). A user
will then be able to debug their OCaml program by using (perhaps an augmented)
\lstinline{gdb} on the generated C code.

In order to solve the problem of ``seeing through'' polymorphism, I will use a
library written by my supervisor, \lstinline{liballocs}, which keeps track of
runtime allocation metadata (including their types) with low overhead. This
will allow the debugger to inspect the allocation corresponding to the input to
\lstinline{my_rev}, for instance, and conclude that it is operating on lists
with elements of type \lc\lstinline{int}\lnone.


\chapter{Preparation}

Before starting the project, I was fairly comfortable with both the OCaml and
C languages. However, I had no experience with the OCaml compiler codebase, nor
indeed any experience in working on a project as large as it.

The vast majority of my code will be written to be built as part of the OCaml
compiler. The compiler is itself written in OCaml, and is a large and complex
code base developed over the course of over 20 years, consisting of 197k lines
of OCaml and 42k lines of C.\footnote{As counted by the \lstinline!cloc! tool.}

The OCaml compiler processes OCaml code in several phases:

TODO diagram

\section{Common types}\label{common-types}

The compiler represents the name of all variables as \lstinline!Ident.t!, which
is conceptually a tuple of the variable name string and a unique integer. Each
let binding is given its own unique \lstinline!Ident.t! -- once the frontend
has resolved variables using OCaml's scoping and shadowing rules, the rest of
the compiler has the guarantee of globally unique\footnote{Up to module
boundary -- at the \lstinline!Lambda! level intermodule variable references
have already boiled down to record field accesses -- see section
\ref{inter-module-references}.} identifier names.

A \lstinline!type_expr! represents the OCaml type of a particular expression.

\section{\texttt{Parsetree} and \texttt{Typedtree}}

The very first representation used by the compiler is \lstinline!Parsetree!.
This is an Abstract Syntax Tree produced directly from the OCaml source code by
the parser. At this stage all original OCaml features are still present, before
any desugaring has happened yet. For instance, pattern matches are as
originally expressed in the source code.

The typing phase takes a \lstinline!Parsetree! and produces a
\lstinline!Typedtree!. This is the phase that ensures that all expressions are
well-typed. The \lstinline!Typedtree! is almost identical to
\lstinline!Parsetree!. The difference is that every \lstinline!expression! node
in the tree is augmented with the \lstinline!type_expr! -- the expression of
this type.

\section{\texttt{Lambda} IR}

For our purposes, \lstinline!Lambda! is the most important representation in
the OCaml compiler, as it is the starting point for our compiler. This
Intermediate Representation (IR) is based on a heavily augmented lambda calculus.

The pass that compiles \lstinline!Typedtree! into \lstinline!Lambda! IR most
significantly desugars pattern matching into elementary conditionals and
destructuring operations. Also class and module constructs are compiled down to
records.

Notably this pass does NOT provide:

\begin{itemize}
    \item type preservation -- see section \ref{type-information-for-liballocs}
    \item closure conversion -- see section \ref{closures}
    \item uncurrying\footnote{Significantly for us this means
        partial applications and ``overapplications'' are not converted into
        complete applications} -- see section \ref{closures-compiler-support}
\end{itemize}

\subsection{Introduction to \texttt{Lambda}}

Each OCaml file implicitly defines a module, whose name is the same as the
filename capitalised. For instance, \lstinline!test.ml! defines a module named
\lstinline!Test!.

At the core language level\footnote{That is, ignoring the module sublanguage.},
every toplevel statement must be a let-statement. However, there are two
different types. Let-statements which define functions have bodies should not
be executed immediately -- only when the function is called. All other
let-statements should run exactly once when the module is loaded for the first
time. For instance:
\lml\begin{lstlisting}
(* function -- not run immediately *)
let foo () = [ 3 ; 2 ; 1 ]

(* ignored result -- run immediately *)
let _ = foo ()

(* variable -- run immediately *)
let bar = List.sort (-) (foo ())\end{lstlisting}\lnone

This will get translated into the following (abridged) \lstinline!Lambda! code.
\lml\lstset{numbers=left}\begin{lstlisting}
Lseq (
  Lprim (Popaque, [ Lprim (Pgetglobal, [ "List" ]) ]),
  Llet (
    foo_1199,
    Lfunction ([ param_1255 ], ...),
    Lseq (
      Lapply {
        ap_func = foo_1199,
        ap_args = [ Lconst (Const_base (Const_pointer 0)) ]
      },
      Llet (
        bar_1200,
        Lapply {
          ap_func =
            Lprim (Pfield 40, [
              Lprim (Pgetglobal, [ "List" ])
            ]),
          ap_args = [ ... ]
        },
        Lprim (Pmakeblock (0, Immutable), [foo_1199, bar_1200])
      )
    )
  )
)\end{lstlisting}\lnone\lstset{numbers=none}

There are several things to note about the \lstinline!lambda! tree produced.
\begin{enumerate}
  \item \lml\lstinline!let!\lnone{} gets translated to \lstinline!Llet!, as can
    be seen on lines 3 and 11 of the output. The tree ends up very nested, as
    \lstinline!Let! constructor takes as
		its last argument a \lstinline!lambda!
    representing the rest of the module. This mirrors the form
    of a (non-toplevel) \lml\lstinline!let ... in ...!\lnone{} expression in OCaml,
    in contrast to a more imperative style \lstinline!var ...; var ...;!.
    Note that although one does not write the \lml\lstinline!in!\lnone{} keyword
		at the top-level, under the hood it desugars to this form regardless.
  \item All variable references are represented using \lstinline!Ident.t! (see
    \ref{common-types}), denoted here using an underscore between name and numeric
    identifier.
  \item On line 6 of the output, it can be seen that the
    \lml\lstinline!let _ = ...!\lnone{} construct desugars to the \lstinline!Lseq(l1, l2)!
    constructor, which is used to represent the imperative \lstinline!;! operator.
  \item On line 5, a function is defined, represented by the
    \lstinline!Lfunction! constructor. The body of the function (of type
    \lstinline!lambda!) is omitted for brevity.
  \item On line 7, the \lstinline!foo! function is applied using
    \lstinline!Lapply!, which takes a record containing (amongst other things)
    the function and the arguments to apply.
  \item On line 13, \lstinline!List.sort! is applied. Note how inter-module
    references are represented as \lstinline!Pfield! accesses (effectively an
    array index) from a globally defined module object
    -- as described below in \ref{inter-module-references}.
  \item Line 20 constructs the ``return value'' of the \lstinline!lambda!
    expression. This is a module object which is reexported globally under the
    module's name.
\end{enumerate}

\subsection{Inter-module references}\label{inter-module-references}

Each \lstinline!.ml! file in OCaml implicitly defines a toplevel module. The
representation the OCaml compiler compiles moules to at the \lstinline!Lambda!
level is as an ``array''\footnote{Technically a record, which is stored as a
block of contiguous word-sized values, and can be indexed into by integer
offset.} of values, the order of which is defined by the OCaml compiler (likely
based on the order of values in the \texttt{.mli} interface file).

At the lambda IR all inter-modular value/function accesses have already been
lowered to \lstinline!getfield! operations on module objects. For instance, a
call to \lstinline!Foo.bar! will already be represented by something like
\lstinline!getfield Foo 1!. The ordering of values in modules is determined by
the OCaml compiler based on the module's interface (\lstinline!.mli! file if it
exists). This scheme implicitly handles data abstraction for us.

\section{Investigating C AST representations and printing}

My compiler is required to output C code, so a way was required to represent C
as a syntax tree that can be easily manipulated. My supervisor suggested the
use of \lstinline!cil!, a C ``intermediate language'' which is capable of
semantically representing all C programs using a minimised subset of the language.

However, I came to the conclusion that this wouldn't be a good fit for my project, because
 CIL is, in a sense, trying to accomplish the opposite of what I want. CIL
 tries to represent a minimal subset of C, and allow transformations to be
 performed on this. On the other hand I'd like to represent the useful subset
 of C which I can use to compile OCaml constructs to.


\section{Investigating closure possibilities}

Supporting closures in C is one of the first identified difficulty points.
Some preliminary investigation was done towards possible external libraries
that could be used to implement them. One of these, \lstinline!libffi!,
was suggested by my supervisor.

However, I came to the conclusion that \lstinline!libffi!'s API was too generic
and complex for the very specific use case that I had in mind. In addition, I
wasn't sure whether the library would give me enough control. Finally, I wanted
to take on the challenge of implementing closures myself, so that I could gain
a better understanding of the technique.

\section{\texttt{liballocs}}

\lstinline!liballocs! is a C library (and accompanying toolchain wrapper)
written and maintained by my supervisor, Stephen Kell. The library transparently
keeps track of the sizes and types of all allocated memory, with no
modifications required. Given an arbitrary valid pointer, \lstinline!liballocs!
can return information about the start and the extend of the corresponding
allocated block, and also the C type of the allocation.


\chapter{Implementation}

\section{Summary and structure of code}

\begin{enumerate}
  \item the modified driver (\lstinline!driver/compile.ml! -- section\ref{modified-compiler-driver})
  \item the C compilation stage (\lstinline!bytecomp/liballocs.ml! -- section \ref{module-c})
  \item the runtime
    \begin{enumerate}
      \item OCaml standard library (\lstinline!stdlib_liballocs!)
      \item C runtime library (\lstinline!liballocs_runtime.c!)
    \end{enumerate}
  \item build script (\lstinline!build_liballocs.sh! -- section \ref{build-process})
  \item test script (\lstinline!run_tests.sh! -- section \ref{regression-testing})
  \item benchmark scripts (\lstinline!benchmark.sh! and \lstinline!plot.r! -- section \ref{benchmarks})
\end{enumerate}

My runtime is implemented assuming a fairly particular setup. A 64-bit
Linux environment is required, due to my value representation (section
\ref{value-representation}) and closure implementation (section
\ref{closures}).

The stages of my C compiler backend are as follows:

\begin{center}
  \includegraphics[width=16cm]{compiler_structure}
\end{center}

\subsection{\texttt{module C}: the extended C abstract syntax tree datatype}\label{module-c}

I have defined a datatype representing a C-like syntax tree. Not all C features
are modelled -- only the constructs that my compiler needs to produce.

The tree datatype is slightly more expressive than standard ANSI C. These extra
features are rewritten into standard C in a later pass, as detailed later in
section \ref{module-fixup}.

The following datatypes are defined for use inside my compiler. Their output representations in the C code are described in later sections.

\begin{itemize}
  \item
    \lstinline!C.ctype! represents a C type. Notable constructors include:

    \begin{itemize}
        \item \lstinline!C_Pointer of C.ctype!;
        \item \lstinline!C_Value!, a word-sized type capable of representing
          any OCaml value -- described later in section \ref{value-representation};
        \item \lstinline!C_Int!;
        \item \lstinline!C_Double!;
        \item \lstinline!C_Struct of Ident.t * (C.ctype * string) list!;
        \item \lstinline!C_FunPointer of C.ctype * C.ctype list! taking return
            type and argument types.
    \end{itemize}

    For instance, the type of a function pointer \lstinline!void (*)(double *)! is
    represented in my OCaml code as
    \lstinline!C_FunPointer (C_Void, C_Pointer C_Double)!.
  \item
    \lstinline!C.expression! represents an expression -- program fragments that
    evaluate to a value (possibly of type \lstinline!void!). Notable
    constructors for this datatype include:
    \lml\begin{itemize}
        \item Data literals of various types:
            \begin{itemize}
                \item \lstinline!C_IntLiteral of Int64.t!
                \item \lstinline!C_StringLiteral of string!
                \item \lstinline!C_FloatLiteral of string!\footnote{Floats are
                    always represented in the OCaml compiler as strings, to
                    prevent rounding errors.}
                \item \lstinline!C_CharLiteral of char!
                \item \lstinline!C_PointerLiteral of int!\footnote{This
                    doesn't take \lstinline!int64! as might be expected, as it
                    is used to represent lambda's \lstinline!Const_pointer of int!,
                    which seems only to be used by the compiler to represent
                    \lstinline!NULL!.}
            \end{itemize}
        \item Variables. Two different kinds are distinguished:
          \begin{itemize}
            \item \lstinline!C_Variable of Ident.t! takes an identifier (see section
              \ref{common-types}), and is used for all local variables
              originating from OCaml code. The variables are formatted suffixed
              with their unique integer: \lstinline!variablename_1234!.
            \item \lstinline!C_GlobalVariable of string! takes a string and
              outputs it verbatim -- there is no integer suffix. The compiler
              generates these references when it needs to reference internal
              functions, such as \lstinline!ocaml_liballocs_close! (see section
              \ref{closures-runtime-support}). Cross-references to other
              modules also use these.
          \end{itemize}
        \item \lstinline!C_FunCall of C.expression * C.expression list!
            represents function calls as an expression evaluating to the
            function to be called, and the list of arguments. See section \ref{functions}.
        \item \lstinline!C_BinaryOp of string * expression * expression!
            represents all arithmetic and logical binary operations.
    \end{itemize}\lnone

    For instance, the expression \lstinline!foo + 2! is represented as
    \lml\begin{lstlisting}
C_BinaryOp (C_Variable foo, "+",
            C_IntLiteral (Int64.of_int 2))\end{lstlisting}%
    (where \lstinline!foo : Ident.t! is the identifier representing the name of the
    \lstinline!foo! variable).

    \lnone
  \item
    \lstinline!C.statement! represents a statement -- language constructs such as:
        \lml\begin{itemize}
            \item \lstinline!C_If of expression * statement list * statement list!
            \item \lstinline!C_While of expression * statement list!
            \item \lstinline!C_Return of expression option!
            \item \lstinline!C_Expression of expression!
            \item etc.
        \end{itemize}\lnone
        Note that statements typically contain one or more expressions, whereas
        expressions in standard C cannot contain statements. (This is however
        possible in my AST -- as described below in sections \ref{c-inline-statements} and \ref{c-inline-functions}.)

  \item
    \lstinline!C.toplevel! represents a function or global variable declaration/definition at the toplevel.
        TODO
\end{itemize}

Refer to (appendix -- section TODO) for the complete datatype definition.

\section{Runtime value representation}\label{value-representation}

In the produced C code, \lstinline!ocaml_value_t! is a type which is capable of
representing any OCaml value. This type corresponds to the \lstinline!C_Value!
datatype in my compiler. This type is required to represent polymorphic OCaml
types: for instance a function with a parameter of OCaml type \lml\lstinline!'a!\lnone
would take a C parameter of type \lstinline!ocaml_value_t!.\footnote{As it
turns out, it's easier to represent \textit{all} OCaml values as values of this
type, not just polymorphic ones.}

A simple way of implementing this type is to make all OCaml values boxed. This means
that everything is allocated on the heap, and the variables of type
\lstinline!ocaml_value_t! are all just pointers into the heap. However this has
several significant downsides.

One downside of using boxed objects is that the extra indirection required to
access each variable is very slow. Another is that boxing small types, such as
integers, requires twice as much memory -- one word-sized integer on the heap
and the word-sized pointer to it.

Because of this, my \lstinline!ocaml_value_t! representation is actually
capable of storing some types of value unboxed. We would still like
\lstinline!ocaml_value_t! to be exactly 64-bits in size, so that it fits into a
register. A technique is needed to fit both pointers and \textit{immediates}
(unboxed values such as integers and floating point numbers) into such a
word-sized type. Various such techniques have been used over the years by
high-performance compilers and interpreters:
\begin{enumerate}
  \item \textbf{untagged values}, as used by the D programming language, for
    example. This ``technique'' simply represents each type of value as itself.
    Note that there is no way to tell what type the value is just from inspecting the value itself.

    Although OCaml is an example of a statically typechecked language which would
    still be correct without runtime type information\footnote{Almost -- OCaml's
    ``polymorphic comparisons'' feature require a limited form of value tagging
    to support structural comparison.}, this approach is not used by the upstream
    compiler. This is because any garbage collector that works with such a
    value representation must be conservative, which has many
    disadvantages.
  \item \textbf{tagged pointers}, as used by OCaml's upstream compiler, the V8
    JavaScript engine, and many others. This technique steals the least
    significant bit of each 64-bit value to use as a ``tag bit'', signifying whether
    that value is boxed or not. In OCaml's scheme, an unset tag bit indicates
    that the value is a pointer, and a set bit indicates an immediate 63-bit integer.
    The reason this works is because pointers to valid OCaml objects are always
    8-byte aligned, which means that all valid pointers have the bottom
    three bits zeroed. The disadvantage of this representation is that there is
    no space to represent doubles -- they must be boxed.
  \item \textbf{NaN boxing}, as used by WebKit's JavaScriptCore engine,
    SpiderMonkey and LuaJIT. This is the scheme I chose to use, because unlike
    the tagged pointers approach, both immediate integers and doubles can be
    represented. The details are described in the next section.
\end{enumerate}

\subsection{NaN boxing}\label{nan-boxing}

NaN boxing allows us to represent doubles unboxed. Our implementation of NaN
boxing was inspired by JavaScriptCore's \cite{jscore}, however the exact choice
of encoding and implementation details are original.

The key idea is that Not-a-Number (NaN) values in IEEE 754 double-precision
floating point values take up a needlessly large range of the 64-bit space. In
particular, any of the $2^{53}-1$ numbers with an exponent of \texttt{0x7FF} and
non-zero mantissa is a NaN value. There are only four different NaNs: plus or
minus quiet ($\pm$qNaN) and signalling ($\pm$sNaN). Modern CPUs only ever use
one specific (canonical) bit representation for each type of NaN, which leaves
the rest of the range to embed other types of values into.

\begin{tabular}{c c | c c | c}
    63..52 & 51..0 & 63..52 & 51..0 & purpose \\
    \lstinline!fff! & \lstinline!0000000000000! & \lstinline!fff! & \lstinline!1000000000000! & Negative infinity \\
    \lstinline!fff! & \lstinline!4000000000000! & \lstinline!fff! & \lstinline!5000000000000! & Negative signalling NaN (canonical) \\
    \lstinline!fff! & \lstinline!8000000000000! & \lstinline!fff! & \lstinline!9000000000000! & Negative quiet NaN (canonical) \\
    \lstinline!fff! & \lstinline!b000000000000! & \lstinline!fff! & \lstinline!c000000000000! & Integers (50-bit space) \\
    \lstinline!fff! & \lstinline!effffffffffff! & \lstinline!fff! & \lstinline!fffffffffffff! & Integers (50-bit space) \\
    \lstinline!fff! & \lstinline!f000000000000! & \lstinline!000! & \lstinline!0000000000000! & Pointers (48-bit space) \\
    \lstinline!fff! & \lstinline!fffffffffffff! & \lstinline!000! & \lstinline!0ffffffffffff! & Pointers (48-bit space)
\end{tabular}

Using this representation \lstinline!ocaml_value_t! can be used to wrap one of the following three types in such a way that the original type of the value can be discriminated (i.e. the ranges do not overlap):
\begin{enumerate}
  \item an unboxed (or \textit{immediate}) 50-bit integer;
  \item an unboxed (or \textit{immediate}) double-precision floating point value (\lstinline!double! in C);
  \item a boxed value -- a pointer to a heap-allocated value (\lstinline!ocaml_value_t*! in C).
\end{enumerate}

The actual C type definition of \lstinline!ocaml_value_t! is the following union:
\lc\begin{lstlisting}
union _ocaml_value_t;

typedef union _ocaml_value_t *generic_datap_t;
typedef union _ocaml_value_t (*generic_funcp_t)();

typedef union _ocaml_value_t {
    intptr_t        i;
    generic_datap_t p;
    generic_funcp_t fp;
} ocaml_value_t;
\end{lstlisting}\lnone
Note that we use the \lstinline!i! field for both integers and doubles. This is
because doubles need to be reinterpreted as integers in order to apply the
$2^{48}$ shift as described previously.

Also note that data pointers and function pointers are accessed using different
union fields, despite the fact that both are 64-bit pointers into the same
address space on Linux. This is a quirk of C: casting between these two types
of pointers is undefined behaviour. Interestingly \lstinline!gcc! will indeed
miscompile code that casts betwen these two types.

We define some helper macros in C:
\begin{enumerate}
    \item \lstinline!NEW_I!, \lstinline!NEW_D!, and \lstinline!NEW_P! allow us to
    wrap raw integer, double or pointer values into new \lstinline!ocaml_value_t!.
    These perform the encoding step as described previously. For instance,
    \lstinline!NEW_D! is defined by viewing the double as an integer, and
    adding $2^{48}$, as follows:

\lc\begin{lstlisting}
static intptr_t __double_encode(double x) {
    union {
        double d;
        intptr_t i;
    } s = {.d = x};
    return s.i + (1LL<<48);
}
#define NEW_D(v) ((ocaml_value_t){.i = __double_encode(v)})\end{lstlisting}\lnone

    \item \lstinline!GET_I!, \lstinline!GET_D!, and \lstinline!GET_P! allow us to
        unwrap an \lstinline{ocaml_value_t} back into a raw integer, double or
        pointer value respectively. For instance, \lstinline!GET_D! is defined
        as:
\lc\begin{lstlisting}
#define GET_D(v) (__double_decode((v).i))\end{lstlisting}\lnone
        where \lstinline!__double_decode! is the inverse of the \lstinline!__double_encode! operation defined previously.

    \item \lstinline!IS_I!, \lstinline!IS_D!, and \lstinline!IS_P! allow us to
        discriminate which type of value is wrapped inside an
				\lstinline{ocaml_value_t}. This is done by simple integer range tests
				-- for instance:
\lc\begin{lstlisting}
#define IS_I(v) \
  ((uintptr_t) (v).i >= 0xfffc000000000000ULL)\end{lstlisting}\lnone
\end{enumerate}

\subsection{50-bit integer arithmetic}\label{50-bit-integer}

NaN boxing limits our integers to be 50-bit sized. Luckily, the size of OCaml's
standard unboxed integer is deliberately left unspecified -- in fact the
upstream compiler uses either 31-bit or 63-bit integers depending on the
platform.

Interestingly, most native word-sized arithmetic operations work correctly on non-word-sized integers, due to the properties of modular arithmetic and twos complement representation. For instance, consider two 50-bit integers stored in 64-bit registers, with arbitrary values for the top 14 bits. A 64-bit multiply of the two registers will generate the correct answer in the bottom 50 bits of the resulting register.

The only cases where non-word sized integers need careful treatment are operations where more significant bits in the input can influence less significant bits in the output, such as the right shift and divide operations. OCaml has two shifts:
\begin{itemize}
  \item logical shift, where the shifted-in bits are set to zero;
  \item arithmetic shift, where the shifted-in bits are set to the sign bit.
\end{itemize}

Logical right shift (lsr) is relatively simple -- first set the top 14 bits to zero by using a mask, then perform a native-width logical right shift.

Arithmetic right shift (asr) and division are trickier. We first need to
``clean up'' the top 14 bits by extending our real sign bit (bit 49) into them.
This can be achieved using the following C bitfield trick:
\lc\begin{lstlisting}
static intptr_t __sext50(intptr_t x) {
    struct {
        intptr_t x : 50;
    } s = {x};
    return s.x;
}
\end{lstlisting}\lnone

This defines a bitfield integer which is logically 50 bits long. We write
\lstinline!x! into it, and then read out a value of type \lstinline!intptr_t!
(which is 64 bits long). C semantics cause the 50-bit field to be sign extended
into the rest of the integer, which is exactly the operation we want.\footnote{
The compiler will likely implement this under the hood as
\lstinline!(x lsl 14) asr 14!.}

\subsection{Casting \texttt{ctype}s}

First, define the \textit{kind} of a non-\lstinline!C_Value! \lstinline!ctype!
as one of the following: integer-like, float-like, data-pointer-like, or
function-pointer-like.

The operation of casting from an expression of \lstinline!ctype! ``source''
into type ``target'' is defined as below:

\begin{enumerate}
  \item If source and target are the same, nothing needs to be done;
  \item If source is \lstinline!C_Value! and target is not, then we need to
    unwrap the expression. Assuming the cast is valid, then use the appropriate
    \lstinline!GET_*! macro to retrieve the original value;
  \item If target is \lstinline!C_Value! and source is not, then we need to
    wrap the expression using the appropriate \lstinline!NEW_*! macro;
  \item Otherwise use a C cast to the target type.
\end{enumerate}

\subsection{\texttt{module Translate}: compilation from lambda IR to C AST}

The implementation of \lstinline!Translate! is done via a recursive tree-walk
over the \lstinline!Lambda! tree. Three mutually recursive functions each
target different types of C program fragment:

TODO

Note that each translation function also returns the C return type
(\lstinline!C.ctype!) of the expression or statement. This is for the purposes of ``casting'', as defined earlier.

Unfortunately the lambda IR is not documented anywhere, so the semantics
of these instructions were divined through reverse engineering and code diving.
OCaml's expressive type system often hinted at the semantics of various
parts of the code.

\subsubsection{Primitive operations}

``Primitive'' operations in \lstinline!Lambda! are represented by
\begin{lstlisting}
Lprim (primitive, args)\end{lstlisting}
where \lstinline!args! are a list of \lstinline!lambda! terms, and \lstinline!primitive! is one of:
\begin{enumerate}
  \item \lstinline!Pidentity! which returns its sole argument verbatim;
  \item \lstinline!Pignore! which evaluates and ignores the result of its sole argument;
  \item \lstinline!Popaque! which for our purposes can be treated the same as
    \lstinline!Pidentity!. However, this seems to have a special meaning inside
    the module. Any external modules that the current compilation unit
    depends on are listed as a sequence of
    \lstinline!Lprim (Popaque, [external_module])!;
  \item \lstinline!Pdirapply! and \lstinline!Prevapply! 
  \item \lstinline!Pgetglobal! TODO
  \item \lstinline!Pfield! and \lstinline!Pfloatfield! TODO
  \item \lstinline!Psetfield! TODO
  \item \lstinline!Pmakeblock! TODO
  \item various unary and binary operations TODO
  \item \lstinline!Pccall! TODO
  \item \lstinline!Praise! TODO
  \item \lstinline!Pstringlength! TODO
  \item \lstinline!Pstringrefs! TODO
\end{enumerate}

\subsubsection{Structured constants}

TODO

\subsubsection{Events}

\subsubsection{Other \texttt{Lambda} operations}

\begin{enumerate}
  \item \lstinline!Lvar! TODO
  \item \lstinline!Lfunction! TODO
  \item \lstinline!Lapply! TODO

    ---

  \item \lstinline!Llet!, \lstinline!Lletrec! TODO
  \item \lstinline!Lsequence! TODO
  \item \lstinline!Lifthenelse! TODO
  \item \lstinline!Lwhile! -- see section \ref{while-loops}
  \item \lstinline!Lfor! -- see section \ref{for-loops}
  \item \lstinline!Lstringswitch! -- see section \ref{stringswitch}
  \item \lstinline!Ltrywith!, \lstinline!Lstaticcatch!, \lstinline!Lstaticraise! -- see section \ref{exceptions}
\end{enumerate}

\subsubsection{Inline statements}\label{c-inline-statements}

The fact that C language makes a distinction between ``statements'' and
``expressions'' makes it less expressive than OCaml, as all core language
features in OCaml can be used as expressions. For instance, consider the
translation of the following OCaml code:

\begin{lstlisting}
let x = if foo then (if bar then 1 else 2) else 3
\end{lstlisting}

Clearly a direct translation of this wouldn't be possible, as \lstinline!if!
statements cannot be used as expressions in C. The ternary operator
\lstinline!?:! exists in C as an expression analogue of \lstinline!if!.
However, it isn't used by my compiler for two reasons.  Firstly in the
interests of readability -- nested ternary operators get hard to read very
quickly. The second reason is that debuggability of if statements would be
hampered by the fact that debuggers tend not to be able to single-step easily
from the condition to the body.

Even if the ternary operator were used, there are other statements that
cannot be made into expressions as easily. An example is the let-statement,
which translates to variable declarations in C. Hence, a solution to this
general problem would still be required.

The way that we handle this is by extending our \lstinline!C.expression! so
that statements can become expressions.  We add a new constructor
\lstinline!C_InlineRevStatements of C.statement! to the
\lstinline!C.expression! type, which allows us to use any C statement as if it
were an expression.

By doing this, our example from above can be translated directly, simply by
wrapping the \lstinline!C_If! statements up as an ``inline statement block'',
which are a list of statements disguised as a single expression, where an
inline statement evaluates to the ``value'' of the last statement in the block.

See section \ref{module-fixup} for more details.


\subsubsection{Inline function definitions (lambdas)}\label{c-inline-functions}

\begin{lstlisting}
let x = (fun x -> x + 1) 2
\end{lstlisting}

\subsection{\texttt{module Fixup}: translation from extended-C AST to valid C AST}\label{module-fixup}

Similar to \lstinline!Translate!, the implementation of \lstinline!Fixup! is
done via a recursive tree-walk. Three mutually recursive functions each visit
different types of nodes:

\begin{lstlisting}
var fixup_let_defs :
  Fixup.t -> C.statement list -> C.let_definition list ->
  C.statement list

var fixup_expression :
  Fixup.t -> C.statement list -> C.expression ->
  C.statement list * C.expression

var fixup_rev_statements :
  Fixup.t -> C.statement list -> C.statement list ->
  C.statement list
\end{lstlisting}

Each fixup function is invoked in the form \lstinline!fixup_foo t accum foo!

We define a single operation which is used during the process of extracting an
expression from an inline block:

\begin{lstlisting}
assign_last_value_of_statement
\end{lstlisting}

TODO

\subsection{\texttt{module Emitcode}: outputting C AST to a file}\label{emitcode}

TODO

\subsubsection{Identifier legalisation}

Not all OCaml identifiers are legal C identifiers. TODO

\subsubsection{Typed identifier output}

C outputs normal variables and function pointers in different styles. TODO

\subsection{Modified compiler driver}\label{modified-compiler-driver}

Support was added to the \lstinline!ocamlc! driver binary to generate and
output C code. A new flag \lstinline!-target-liballocs! was added. After the
simplified lambda IR is generated as usual, the presence of this flag will
trigger the additional phase of compiling and outputting the C code in addition
to running the rest of the compiler pipeline.

\section{Build process}\label{build-process}

TODO

Also see \ref{module-list}.


\section{Basic constructs}

\subsection{Functions and complete application}\label{functions}

TODO

Partial application and closures are discussed later in section \ref{closures}.

\subsection{Mutually recursive functions}\label{mutually-recursive-functions}

TODO

\subsection{Mutually recursive definitions}\label{mutually-recursive-values}

Consider the OCaml expression

\begin{lstlisting}
let rec a = 1::b and b = 2::a in ...
\end{lstlisting}

This defines a mutually recursive \textit{value} -- creating a infinite
(cyclic) list of period 2. The value of \lstinline!a! will be
\lstinline!1::2::1::2::1:: ...!

In order to ensure correct semantics even in the presence of mutually recursive
value definitions, my compiler separates the variable definition process into
three phases:

\begin{enumerate}
  \item \textbf{Allocation}: first the required memory for each variable are
    allocated using \lstinline!malloc!;
  \item \textbf{Closure creation (optional)}: (TODO: move this to the closure section)  at this point the memory
    addresses of variables are known, and so can be frozen into closures as
    needed. The process is described in great detail in section \ref{closures}
    (TODO: actually write this section);
  \item \textbf{Initialisation}: finally, the contents of the variables are
    set.
\end{enumerate}

The resulting C code will look like:

\begin{lstlisting}
// Phase 1: allocation
ocaml_value_t a_1213 = NEW_P(malloc(sizeof(ocaml_value_t) * 2));
ocaml_value_t b_1213 = NEW_P(malloc(sizeof(ocaml_value_t) * 2));

// Phase 3: initialisation
a_1213[0] = 1;
a_1213[1] = b_1213;
b_1213[0] = 2;
b_1213[1] = a_1213;
\end{lstlisting}
(TODO: fix this once list malloc typing works!)

TODO

\subsection{Imperative-style while loops}\label{while-loops}

TODO

\subsection{Range-based for loops}\label{for-loops}

OCaml's for loops are range-based, coming in two varieties:
\begin{lstlisting}
for i = 1 to 10 do ... done
for i = 10 downto 1 do ... done
\end{lstlisting}

The range limits are inclusive.

This needs to be translated at some point in into C's more general
initialisation-condition-update for loop. I chose to reflect OCaml's for loop
semantics rather than C's with my \lstinline!C.expression!
constructor, deferring the translation to the \lstinline!Emitcode! stage (see
section \ref{emitcode}).

\lstinline!C_ForInt!

For instance, the first loop from the example above
compiles to:

\begin{lstlisting}
for (int64_t i_1203 = 1, _limit_1212 = 10;
     (i_1203<=_limit_1212);
     (++i_1203)) {
  ...
}
\end{lstlisting}

There's a slight subtlety in that we need to evaluate the range limits exactly
once, for correct semantics when evaluating the range incurs side effects.
Hence the end limit can't be evaluated in the condition part of the C for loop.
Instead we define the end limit as an additional variable in the initialisation
step, and test against the variable instead.

\subsection{String switches}\label{stringswitch}

The \lstinline!Lambda! IR has a specific instruction \lstinline!Lstringswitch!
for string matching. For instance
\begin{lstlisting}
match x with
| "foo" -> 1
| "bar" -> 2
| _     -> 3\end{lstlisting}
is compiled into (in pseudo-\lstinline!Lambda!)
\lstinline!Lstringswitch (x, [("foo", 1), ("bar", 2)], 3)!.

However, C does not have any way to match on strings (\lstinline!char*!) -- the
switch statement only works with ``integral'' types (such as \lstinline!int! or
\lstinline!char!). The idiomatic way to compare strings is by using the
standard library function \lstinline!strcmp!. Hence, we need to translate this
construct into a \lstinline!strcmp! if-ladder:
\begin{lstlisting}
char *__stringswitch_1235 = x_1234;
if (0 == strcmp(__stringswitch_1235, "foo")) {
  1
} else (0 == strcmp(__stringswitch_1235, "bar")) {
  2
} else {
  3
}\end{lstlisting}
Once again we must take care to evaluate \lstinline!x! exactly once, by
assigning the result of evaluation to a variable.

\section{Standard library: \texttt{module Pervasives}}

\subsection{C runtime}

The Pervasives module exposes (and internally uses) a large number of external
predefined runtime functions (such as \lstinline!caml_sys_exit!), normally
provided by the OCaml C runtime library. However, this library makes many
assumptions about OCaml's tagged value representation, and is deeply integrated
with the garbage collector. Hence new implementations of these functions had to
be made.

I selectively implemented functions that were necessary for the subset of
stdlib functionality that was required to run my tests and benchmarks.

See appendix TODO for details.

\subsection{Printing to \texttt{stdout} and \texttt{stderr}}\label{pervasives-printing}

Two sets of C runtime functions had to be implemented in order to support
Pervasives functions such as \lstinline!print_int!. Int-to-string formatting
and string printing are all delegated to the runtime library.

TODO

\section{Inter-module linking}

Recall from section \ref{inter-module-references} that inter-module references
(such as \lstinline!List.sort!) are compiled to record field accesses at the
\lstinline!Lambda! level. The top-level module constructor of the currently
compiled module returns a block which represents the record to be exported to
other modules.

The way that we translate this concept to C is by representing a module
\lstinline!foo! as a C compilation unit \lstinline!foo.c! exposing the following:
\lc\begin{lstlisting}
ocaml_value_t *Foo;  // the "module object"
void Foo__init();    // the "module constructor"
\end{lstlisting}\lnone
The module
constructor function is idempotent, and after a call to it the module object is
guaranteed to contain valid values. Furthermore all global side effects in
\lstinline!foo.ml! are also performed when the module is initialised for the
first time.

Note that \lstinline!Foo! may well depend on other modules, such as
\lstinline!Pervasives!. Recall that these were represented as
\lstinline{Popaque} references at the root of the \lstinline!lambda! tree.
In \lstinline!foo.c! any such dependencies are represented as predeclarations
of the module objects and constructors, and calls to constructors at the start
of \lstinline!Foo__init!. The skeleton of such a module is shown in the listing
below:
\lc\begin{lstlisting}
#include "liballocs_runtime.h"

void Pervasives__init();
extern ocaml_value_t *Pervasives;

ocaml_value_t *Foo;

void Foo__init() {
    if (Foo) {
        return;
    } else {
        Pervasives__init();

        // allocate and construct module object Foo
    }
}
\end{lstlisting}\lnone

\section{Type information for \texttt{liballocs}}\label{type-information-for-liballocs}

\subsection{\texttt{Pmakeblock}}

TODO

\section{Exceptions}\label{exceptions}

OCaml has support for exceptions: a \lstinline!raise Foo! causes the
exception \lstinline!Foo! to propagate up through stack frames until a
\lstinline!try _ with Foo -> _! block is found.

Interestingly, exceptions is one of the cases where the lambda IR is more
complex than the OCaml language. Lambda distinguishes between static (local)
exceptions, and non-static ones.

Once again, because of the undocumented nature of the lambda IR, the semantics
of these instructions were divined through reverse engineering and code diving.

\subsection{Static exceptions}

Static exceptions are confined to a lexically local scope -- i.e. the raise and
the corresponding try are in the same function. The lambda instructions for
these are \lstinline!Lstaticraise! and \lstinline!Lstaticcatch!.

In this case, we can implement these using the C \lstinline!goto! feature,
which allows control flow to jump non-linearly to another point in the same
function.

The structure gets compiled into the following construct:

\begin{lstlisting}
if (1) {
    /* body */
    // goto label_staticcatch_1;
} else {
label_staticcatch_1:;
    /* handler */
}
\end{lstlisting}

\subsection{Non-static exceptions}

More generally an exception may unwind through several stack frames, and may be
caught in different handlers depending on the dynamic runtime behaviour.

C has a mechanism to perform ``non-local'' jumps using the special library
calls \lstinline!setjmp! and \lstinline!longjmp!. A call to \lstinline!setjmp!
will save the CPU registers at the point the function was called (notably,
including the instruction and stack pointers) into a \lstinline!struct jmpbuf!
that the user provides. Calling \lstinline!longjmp! will then restore the state
of the program, so that execution flow resumes as if the original
\lstinline!setjmp! returned for a second time. \lstinline!setjmp! will return
non-zero iff it is returning for the second time.

I use this mechanism to support exception handling. TODO

\begin{lstlisting}
  if (setjmp(jmp_buf) == 0) {
    // first time
    longjmp(jmp_buf);
  } else {
    // second time
  }
\end{lstlisting}

\lstinline!setjmp! allows control flow to ``unwind'' to the last installed
exception handler. The value of the exception currently being handled is stored
in a global variable known to the compiler, so that exception handlers can
pattern match against it. The exception handler is uninstalled (``popped'' off
the stack of exception handlers) when:
\begin{itemize}
  \item a try block finishes without raising; or
  \item a handler starts executing. This prevents exceptions raised inside the
      handler from incorrectly being recursively handled by itself.
\end{itemize}

The memory representation of an exception contains the stringified name of the
exception, so that if it is propagated all the way up unhandled, the runtime
can print the name of the exception before aborting.

\subsection{Runtime support}

\subsubsection{Toplevel handler}

If an exception propagates all the way to the top without being handled
successfully, the runtime needs to print an error message and abort the
program. This is done by installing a root handler in \lstinline!main! before
calling into OCaml code.

Assuming that the module being compiled is called \lstinline!Test!, the
following is the C \lstinline!main! function:

\begin{lstlisting}
void Test__init();

int main() {
    // set up root exception handler
    OCAML_LIBALLOCS_EXN_PUSH();
    if (0 == OCAML_LIBALLOCS_EXN_SETJMP()) {
        Test__init();
        return 0;
    } else { // catch
        OCAML_LIBALLOCS_EXN_POP();
        fprintf(stderr, "Uncaught OCaml exception: %s\n",
                (const char *)
                  GET_P(GET_P(ocaml_liballocs_get_exn())[0]));
        return 1;
    }
}
\end{lstlisting}

\subsubsection{Builtin exceptions}\label{builtin-exceptions}

A number of important exceptions are embedded fairly deep in the OCaml
language, surprisingly at a lower level than even the \lstinline!Pervasives!
module. OCaml raises some of these exceptions specially for various reasons --
for example the \lstinline!Division_by_zero! OCaml exception is raised when the
corresponding FPU exception occurs.

As these exceptions are not defined in the usual way, in OCaml code, we must
manually declare and instantiate these exceptions in our own C runtime library.
The list of predefined exceptions can be found in \lstinline!typing/predef.ml!.
The C preprocessor quote trick allows us to succinctly define the list of
builtin exceptions statically:

\begin{lstlisting}
#define _QUOTE(x) #x
#define QUOTE(x) _QUOTE(x)
#define DEFINE_BUILTIN_EXCEPTION(name) \
    ocaml_value_t __##name[2] = { \
        NEW_P((generic_datap_t) QUOTE(name)), \
        NEW_I(0) \
    }; \
    ocaml_value_t *name = __##name;

DEFINE_BUILTIN_EXCEPTION(Match_failure)
DEFINE_BUILTIN_EXCEPTION(Assert_failure)
...
\end{lstlisting}

\section{Closures}\label{closures}

C allows function references to be stored in variables, in the form of
``function pointers'' containing the address of the start of the function's
machine code. Calls are performed on function pointers by an indirect jump to
the address (using the \lstinline!call! instruction).

The C language has no notion of closures, which OCaml requires to provide
support for lexical scoping of variables in first-class functions. Closures are
conceptually a tuple of the function pointer and an environment, which stores
the free variables of the closure. Hence, we need to add support for generating
closures manually.

One way to represent closures is as ``fat pointers'', where each closure is
stored as a tuple of two pointers. Note however that in OCaml a closure may be
used whenever a function is expected, so each indirect function call would now
have to check whether the function reference is fat or not -- a significant
runtime cost.

A unified way to call closures and function pointers is desired. In
particular, we'd like the act of closing a C function \lstinline!f_impl! with
an environment \lstinline!env! to produce a fresh function pointer
\lstinline!f_closure!, such that calling
\lstinline!f_closure(1, 2, 3)!
with the standard C calling convention is equivalent to a call to
\lstinline!f_impl(1, 2, 3, env)!.

The technique that we use involves the creation of machine code stubs at
runtime. This approach was pioneered by Breuel \cite{breuel88}. However, our implementation
was developed completely from scratch, and many details differ from the
approach outlined in the paper.

\subsection{Runtime support}\label{closures-runtime-support}

An internal C function \lstinline{ocaml_liballocs_close(f_impl, n_args, env)}
was written, which performs the closing operation as previously described.
\lstinline!f_impl! is the C implementation of the closure -- a function which
takes \lstinline!n_args! arguments along with an extra argument containing the environment.

When \lstinline!ocaml_liballocs_close! is
invoked, a small executable stub is written into an executable
buffer, with the two pointers \lstinline!f_impl! and \lstinline!env! baked in.
Then the address of the start of this stub is returned. The stub is described
in detail below.

Conceptually, the operation can be described as JIT-compiling the following
snippet of pseudo-C code at runtime. (NB: things are a bit more complicated
when \lstinline!n_args!${} > 5$ arguments, as described in the sections below.)

\begin{lstlisting}
ocaml_value_t f_closure(ocaml_value_t arg1,
                        ...,
                        ocaml_value_t argn)
{
    return f_impl(arg1, ..., argn, env);
}
\end{lstlisting}

Note that as implemented, this won't work on anything but 64-bit Linux.

Note that this code must be written to a memory page which has both write and
execute permissions. (This has security implications which mean that additional
precautionary steps must be taken if this technique is to be used in production
code.)

This area of memory is bump allocated. Note that a garbage collector would need
to be taught about this.

\subsubsection{Closing functions that take $\le 5$ arguments}

An Application Binary Interface (ABI) specifies a standardised calling
convention which programs and libraries adhere to. This includes the
specification of the location in registers or memory where function arguments
are passed.

On Unix-like systems\footnote{This does not include Windows!} C uses AMD's x86-64
ABI. The first six arguments are passed in registers in a particular order,
shown in the table below. Hence, when closing a function \lstinline!f! which
originally took five or fewer arguments, there is space to pass \lstinline!env!
in another register.

Conveniently, all six argument registers are also caller-preserved whether they
are used to pass arguments or not. This means that our stub is allowed to
overwrite (or ``clobber'') any of them without having to clean up afterwards.
There are also several other caller-preserved registers, notably
\lstinline!r10!, which we will also make use of.

The following is the table of the register used for each argument in the x86-64
ABI.

\begin{tabular}{ c | c }
  $n$th argument & register \\
  \hline
  1 & \lstinline!rdi! \\
  2 & \lstinline!rsi! \\
  3 & \lstinline!rdx! \\
  4 & \lstinline!rcx! \\
  5 & \lstinline!r8! \\
  6 & \lstinline!r9!
\end{tabular}

We shall place \lstinline!env! into the $(\text{\texttt{n\char`_args}}+1)$-th
argument. Call the corresponding register \lstinline!REG_ENV!.

This is the assembly listing for the machine code generated:

\begin{lstlisting}
mov REG_ENV, <env>
mov r10, <f_impl>
jmp r10
\end{lstlisting}

This works by using two 8-byte immediate \lstinline!mov! instructions, which
each load a fixed constant from the program code, which happen to correspond to
our two pointers \lstinline!env! and \lstinline!f_impl!.
Then \lstinline!f_impl! is tail-called into.

\subsubsection{Closing functions that take $> 5$ arguments}

When \lstinline!n_args! $> 5$, \lstinline!env! needs to get passed in on the
stack instead.

\begin{tabular}{c}
  return address to caller
  \\ \hline\hline
  \lstinline!arg_7!
  \\ \hline
  \vdots
  \\ \hline
  \lstinline!arg_n!
\end{tabular}

However, implementing the direct solution is a little awkward because:
\begin{enumerate}
  \item when we modify the stack, our stub can no longer just tail-call
    into \lstinline!f_impl! -- before returning to the caller we need to undo
    our stack transformation;
  \item we need to tuck \lstinline!env! in under the return address
    stack slot, which would require a large number of stack-twiddling
    instructions.
\end{enumerate}

Luckily, I came up with a neat trick which addresses both issues and remains
performant. It turns out that we can get away with just pushing \lstinline!env!
on top of the stack as follows, before \lstinline!call!ing into
\lstinline!f_impl!. The state of the stack on entry to \lstinline!f_impl! is:

\begin{tabular}{c}
  return address to stub
  \\ \hline\hline
  \lstinline!env!
  \\ \hline
  return address to caller
  \\ \hline
  \lstinline!arg_7!
  \\ \hline
  \vdots
  \\ \hline
  \lstinline!arg_n!
\end{tabular}

By treating the return address to caller as an extra (unused) argument to
\lstinline!f_impl!, it can now access \lstinline!env! through its
(\lstinline{n_args}${}+2$)th argument.

This trick works because our compiler has control over the function signature
of \lstinline{f} -- in this case it'll just generate the following signature:

\begin{lstlisting}
ocaml_value_t f(ocaml_value_t arg_1,
                ...
                ocaml_value_t arg_6,
                ocaml_value_t *env,
                void *unused,
                ocaml_value_t arg_7,
                ...
                ocaml_value_t arg_n);
\end{lstlisting}

Now the machine code stub looks like this:

\begin{lstlisting}
mov r11, <env>
push r11
mov r10, <f_impl>
call r10
pop rcx
ret
\end{lstlisting}

Note the deliberate choice of \lstinline{pop rcx} to remove the
\lstinline{env} address from the stack (instead of, for instance
\lstinline{pop r11} or \lstinline{add rsp, 8}). This is a size optimisation --
the chosen instruction encodes in just one byte.

\subsection{Compiler support}\label{closures-compiler-support}

As OCaml immediate value representations are immutable, we can simply copy the
values of each free variable into the environment at the time of closure
creation.

There is no explicit annotation in the OCaml lambda IR to indicate that a
closure must be created -- the compiler has to perform free-variable analysis
to determine this itself. We handle three separate scenarios where closures
must be created:

\begin{itemize}
    \item \textbf{Function let-binding with non-empty free variable set}:
      \begin{lstlisting}
let make_counter_v1 () =
  let ctr = ref 0 in
  let count () = ctr := !ctr + 1; !ctr in
  count
      \end{lstlisting}
    \item \textbf{Anonymous lambda with non-empty free variable set}:
      \begin{lstlisting}
let make_counter_v2 () =
  let ctr = ref 0 in
  fun () -> (ctr := !ctr + 1; !ctr)
      \end{lstlisting}
    \item \textbf{Partial application}:
      \begin{lstlisting}
let make_counter_v3 () =
  let count ctr () = ctr := !ctr + 1; !ctr in
  count (ref 0)
      \end{lstlisting}
\end{itemize}

TODO: explain what we have to do with these

\subsubsection{Recursive and mutually recursive closures}

Mutually recursive closures share an environment. Hence calls between two
mutually recursive closures must pass the same environment pointer to each
invocation.

Self-recursive closures are a special case of this.



\chapter{Evaluation}

\section{Compiling the OCaml \texttt{List} module}\label{module-list}

As a demonstration of the capabilities of my OCaml compiler, I am able to
directly compile the \lstinline!List! module from the upstream standard
library, with no modifications.

Although many of the functions in the module are very basic (e.g.
\lstinline!hd!), others serve as good demonstrations of recursion, first order
functions and closures, such as \lstinline!filter!, \lstinline!fold_left!. By
far the most complicated function in the module is \lstinline!sort!, which
implements an optimised mergesort.

Compiling the \lstinline!List! module is not just for demonstration purposes,
however. It is a required step in building the compiler, as many benchmarks
rely on this module. The way that \lstinline!List! support is provided to user
code is during tthe linking stage: the user's generated C code is linked
against the generated C code of the \lstinline!Pervasives! and \lstinline!List!
modules.

\section{Regression testing}\label{regression-testing}

As new features have been implemented in the compiler, I've been writing small
tests which ensure the correct functionality of that part of the compiler. In
total 22 separate test files were written, most of which test multiple
variations in a single file. Each commit to the master branch strives to pass
all unit tests\footnote{At the end of my project, there were two expected
  failures: overapplication and submodule function arity inference, as
  described in section \ref{conclusion}}
-- works in progress were done on a separate branch before merging into master
when ready.

A selection of illustrative tests, and the C code produced, is given below.

\begin{enumerate}
    \item \textbf{\texttt{arithmetic}}: tests integer arithmetic and shift
        operations, and floating point operations. In particular the sign
        extension behaviour on 50-bit integers is carefully tested for both
        arithmetic shift and logical shift operations -- as described in
        section \ref{50-bit-integer};
    \item \textbf{\texttt{basic\char`_ops}}: tests compilation and behaviour of
        nested if statements -- section \ref{module-fixup};
    \item \textbf{\texttt{basic\char`_types}}: tests basic types: integers,
        booleans, tuples, lists, reference types
    \item \textbf{\texttt{closure}}: tests the first two styles of closures
        (non-empty free variable set) -- as described in section
        \ref{closures};
    \item \textbf{\texttt{partialapp}}: tests the last style of closure
        (partial application);
    \item \textbf{\texttt{closure\char`_partialapp}}: tests that partial
        application of a closure itself creates a working closure (contrast
        with the partialapp test);
    \item \textbf{\texttt{closure\char`_letrec}}: tests mutually recursive
        closures;
    \item \textbf{\texttt{closure\char`_toplevel}}: ensures that functions with
        free variables that are globally scoped do not needlessly get
        transformed into closures;
    \item \textbf{\texttt{exn}}: tests raising and catching exceptions with and
        without parameters -- section \ref{exceptions};
    \item \textbf{\texttt{exn\char`_2}}: ensure that exception handlers are
        popped correctly;
    \item \textbf{\texttt{exn\char`_builtin}}: tests builtin exceptions --
        section \ref{builtin-exceptions};
    \item \textbf{\texttt{exn\char`_fatal}}: tests that uncaught exceptions
        trigger a message and abort the program;
    \item \textbf{\texttt{while}}: tests imperative-style while loops --
        section \ref{while-loops}.
    \item \textbf{\texttt{for}}: tests range-based for loops, including ranges
        that are negative-lengthed -- section \ref{for-loops};
    \item \textbf{\texttt{letrec}}: tests basic mutually recursive functions --
        section \ref{mutually-recursive-functions};
    \item \textbf{\texttt{letrec\char`_value}}: tests the ``mutually recursive
        values'' OCaml feature -- section \ref{mutually-recursive-values};
    \item \textbf{\texttt{match}}: tests that pattern matching compiles
        correctly;
    \item \textbf{\texttt{print}}: tests standard library printing functions --
        section \ref{pervasives-printing};
    \item \textbf{\texttt{stdlib\char`_list}}: tests standard library
        \lstinline!List! functions -- section \ref{module-list};
    \item \textbf{\texttt{stringswitch}}: tests pattern matching on strings --
        section \ref{stringswitch};

--

    \item \textbf{\texttt{1}}: TODO
    \item \textbf{\texttt{overapplication}}: TODO
\end{enumerate}

\section{Benchmarks}\label{benchmarks}

My benchmarking methodology relies on a shell script \lstinline!benchmark.sh!,
which runs twelve versions of each benchmark:
\begin{itemize}
    \item Bytecode generated by the upstream \lstinline!ocamlc! bytecode compiler. These are run with \lstinline!ocamlrun! (the upstream optimised bytecode interpreter), with default GC settings, and disabled GC settings;
    \item Native code generated by the upstream \lstinline!ocamlopt! native compiler, with default GC settings, and disabled GC settings;
    \item Native code generated by \lstinline!gcc! via my OCaml-to-C compiler, at each of four optimisation levels (\lstinline!-O0!, \lstinline!-O1!, \lstinline!-O2!, \lstinline!-O3!);
    \item Native code generated by \lstinline!clang! via my OCaml-to-C compiler, at each of four optimisation levels.
\end{itemize}

I used R and ggplot2 to process and graph the results, learning the language and library from scratch.

My benchmarks broadly fall into one of three categories.

\subsection{Microbenchmarks}
These microbenchmarks written from scratch by me. These test particular aspects
of the performance of the generated code.

\begin{enumerate}
  \item
    The \textbf{\texttt{closure\char`_create\char`_<n>}} family of benchmarks test the performance of
    creating closures which take $n$ arguments and capture 1 environment value.

  \item
    The \textbf{\texttt{closure\char`_invoke\char`_<n>}} family of benchmarks the performance of
    invoking closures which take $n$ arguments and capture 1 environment value.

    As described in section \ref{closures}, invoking closures which take $n >
    5$ arguments requires more work to be done by the generated code stub.

    TODO

  \item
    The \textbf{\texttt{closure\char`_capture\char`_<n>}} family of benchmarks the performance
    of invoking closures which take 1 argument and capture $n$ variables from their environment.

  \item

  The \textbf{\texttt{list\char`_sort}} benchmark was written from scratch, to test the
  performance of the unmodified pure-OCaml standard library \lstinline!List.sort!
  routine (see section \ref{module-list}).

  The routine only creates a constant number of closures, but makes heavy use of
  closure invocation and allocates heavily due to the list operations it
  performs.
\end{enumerate}

\subsection{\texttt{operf-micro} benchmark suite}
These are various sized benchmarks adapted from the OCamlPro's
      \lstinline!operf-micro! benchmark suite. These needed adapting before
      they could be used, due to being dependent on an OCaml-side framework
      which performs timing and measures GC statistics, features which are not
      supported by my compiler.
\begin{enumerate}

  \item
    The \textbf{\texttt{fibonacci}} benchmark was adapted from the \lstinline!fibonnaci!
[\textit{sic}] benchmark in \lstinline!operf-micro!.

This simple microbenchmark implements the naive (non-memoising) recursive
Fibonacci function, and uses it to evaluate the $40$-th Fibonacci number.

The benchmark primarily stress-tests the speed of function calls, as the cost
of invoking recursive calls dominates the amount of work done inside each call.

\item

  The \textbf{\texttt{lens}} benchmark implements a Haskell-style lens (otherwise known as
functional references), and then uses lenses to operate on a
\lstinline!rectangle! record type.

This makes usage of records and higher order functions, creating a very large
number of closures.

\item

  The \textbf{\texttt{sieve}} benchmark implements a linked-list sieve of Eratosthenes.

This benchmark performs many list operations and is very allocation-heavy.

\item

  The \textbf{\texttt{vector\char`_functor}} benchmark implements 2D and 3D vectors in two
different styles -- directly and by using a generic functor. It then uses these
implementations to create and calculate the dot product of $10^6$ 2D and 3D
vectors.

This benchmark allocates many records, and performs floating point operations.
\end{enumerate}

\subsection{Macrobenchmarks}
These are larger benchmarks written by me, as solutions to Project Euler problems.

\begin{enumerate}
\item

The \textbf{\texttt{p153}} benchmark implements a solution to Project Euler problem 153.

This makes usage of exceptions to break out of a recursive loop early.

\item
  The \textbf{\texttt{p156}} benchmark implements a solution to Project Euler problem 156.

This makes heavy use of recursion and imperative-style \lstinline!for! loops.

\item
  The \textbf{\texttt{p182}} benchmark implements a solution to Project Euler problem 182.

This makes use of a tail-recursive GCD implementation, a counter reference and imperative-style \lstinline!for! loops.

\item
  The \textbf{\texttt{p183}} benchmark implements a solution to Project Euler problem 183.

This makes heavy use of both integer and floating point arithmetic (\lstinline!log!, \lstinline!exp!, floating point division).
\end{enumerate}

\chapter{Conclusion}\label{conclusion}

The project was technically challenging, as I had to work with an unfamiliar
compiler's internals, as well as implementing a new backend from scratch.

My original motivations for this project were the following:
\begin{enumerate}
    \item \textbf{Feasibility}: my project was completely successful in
      demonstrating that compiling OCaml into C code is a feasible task. Many
      OCaml constructs are already supported, and the ones that are not
      (detailed below) were mostly omitted due to time constraints, rather than
      technical ones;
    \item \textbf{Performance}: despite not worrying specifically about
      generating performant C code in my compiler, the benchmarks show that
      the compiled C executables already perform competitively -- matching or
      exceeding OCaml bytecode performance in most cases, when closure creation
      doesn't dominate runtime;
    \item \textbf{Observability}: TODO;
    \item \textbf{Portability}: my implementation in its current state has two
      parts which hinder portability by assuming the generated code is being
      run on 64-bit Linux:
      \begin{itemize}
        \item
          My value representation (section \ref{value-representation}) assumes
          64-bit sized registers so that each value fits in a register.
          In fact, this is not actually a portability problem as it will still
          work on 32-bit target, just somewhat inefficiently;
        \item The closure implementation on the other hand does currently have a hard
          dependency on 64-bit Linux, due to the fact that the hardcoded
          sequence of opcodes is specific to this CPU and ABI. Because of this
          I somewhat regret my choice of implementing closures from scratch --
          if I had taken advantage of a widely-ported library such as
          \lstinline!libffi!, then portability would have been completely
          achievable.
      \end{itemize}
\end{enumerate}

Limitations:

\begin{itemize}
  \item No tag in blocks. This means no support for variants
  \item ``Overapplication'' uncurrying
  \item Large parts of the standard library are unimplemented. Significantly \lstinline!Array!
  \item Inter-module function arity is unknown -- cannot partially apply or overapply (TODO: is this true?)
  \item No liballocs type info for \lstinline!structured\char`_constant!
  \item No polymorphic comparisons, but...

\end{itemize}
%TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\begin{thebibliography}{1}

\bibitem{breuel88}
  Thomas Breuel,
  \emph{Lexical Closures for C++},
  In Proc. USENIX C++ Conf., pages 293-304,
  Denver, CO, October 1988.  \\ \url{http://www.cl.cam.ac.uk/~srk31/teaching/redist/breuel88lexical.pdf}

\bibitem{jscore}
  WebKit authors,
  \emph{JSValue.h}
  \url{https://github.com/WebKit/webkit/blob/master/Source/JavaScriptCore/runtime/JSCJSValue.h}

\bibitem{dolan16}
  Stephen Dolan,
  \emph{Malfunctional Programming},
  ML Workshop, 2016.  \\ \url{https://www.cl.cam.ac.uk/~sd601/papers/malfunction.pdf}

\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

%\chapter{Latex source}
%
%\section{diss.tex}
%{\scriptsize\verbatiminput{diss.tex}}
%
%\section{proposal.tex}
%{\scriptsize\verbatiminput{proposal.tex}}
%
%\chapter{Makefile}
%
%\section{makefile}\label{makefile}
%%{\scriptsize\verbatiminput{makefile.txt}}
%
%%\section{refs.bib}
%%{\scriptsize\verbatiminput{refs.bib}}
%
%
\chapter{Project Proposal}

%\input{proposal}

\end{document}
